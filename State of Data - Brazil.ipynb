{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Descrição do Problema, Dados e Variáveis**\n",
    "\n",
    "#### **Problema**\n",
    "O problema abordado pelo State of Data Brazil 2023 é o mapeamento do mercado de trabalho na área de dados no Brasil. O objetivo é identificar tendências, desafios e oportunidades para profissionais de dados, como cientistas de dados, engenheiros de dados e analistas de dados. A pesquisa busca compreender aspectos como perfis profissionais, remuneração, rotatividade, impacto do trabalho remoto, uso de tecnologias emergentes (como AI Generativa e LLMs) e fatores de satisfação no ambiente de trabalho.\n",
    "\n",
    "\n",
    "Aqui está a versão reorganizada:  \n",
    "\n",
    "---\n",
    "\n",
    "#### **Descrição das Variáveis**  \n",
    "\n",
    "##### **Informações Pessoais**  \n",
    "- **Identificador único para cada respondente**: `P0`  \n",
    "- **Idade do respondente**: `P1_a`  \n",
    "- **Faixa etária do respondente**: `P1_a_1`  \n",
    "- **Gênero do respondente**: `P1_b`  \n",
    "- **Cor, raça ou etnia do respondente**: `P1_c`  \n",
    "- **Indica se o respondente é uma pessoa com deficiência (PCD)**: `P1_d`  \n",
    "\n",
    "#### **Impacto na Experiência Profissional**  \n",
    "- **Indica se a experiência profissional do respondente foi afetada**: `P1_e`  \n",
    "  - **O respondente acredita que sua experiência profissional não foi prejudicada**: `P1_e_1`  \n",
    "  - **A experiência profissional foi prejudicada devido à cor, raça ou etnia**: `P1_e_2`  \n",
    "  - **A experiência profissional foi prejudicada devido à identidade de gênero**: `P1_e_3`  \n",
    "  - **A experiência profissional foi prejudicada devido ao fato de ser PCD**: `P1_e_4`  \n",
    "\n",
    "#### **Aspectos Profissionais Prejudicados**  \n",
    "- **Aspectos da experiência profissional impactados**: `P1_f`  \n",
    "  - **Quantidade de vagas recebidas**: `P1_f_1`  \n",
    "  - **Nível das vagas em relação à experiência**: `P1_f_2`  \n",
    "  - **Sucesso em processos seletivos e entrevistas**: `P1_f_3`  \n",
    "  - **Oportunidades de crescimento profissional**: `P1_f_4`  \n",
    "  - **Rapidez com que ocorre a progressão na carreira**: `P1_f_5`  \n",
    "  - **Pressão e nível de stress no trabalho**: `P1_f_6`  \n",
    "  - **Consideração dada às ideias do respondente**: `P1_f_7`  \n",
    "  - **Relação com colegas no dia a dia**: `P1_f_8`  \n",
    "  - **Relação com colegas em momentos de integração e eventos sociais**: `P1_f_9`  \n",
    "\n",
    "#### **Localização**  \n",
    "- **Indica se o respondente reside no Brasil**: `P1_g`  \n",
    "- **Estado onde o respondente mora**: `P1_i`  \n",
    "\n",
    "#### **Atividades Profissionais Específicas**  \n",
    "- **O respondente cria e mantém a infraestrutura onde seus modelos e soluções rodam (clusters, servidores, APIs, containers, etc.)**: `P8_d_11`  \n",
    "- **O respondente treina e aplica Modelos de Linguagem de Grande Escala (LLMs) para solucionar problemas de negócio**: `P8_d_12`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get File Path and load Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_path():\n",
    "    import os\n",
    "    # Load the data\n",
    "    if os.path.exists('/kaggle'):\n",
    "        file_path = '/kaggle/input/state-of-data-brazil-2023/State_of_data_BR_2023_Kaggle - df_survey_2023.csv'\n",
    "    else:\n",
    "        default_directory = '/home/nerton/Projects/kaggle'\n",
    "        os.chdir(default_directory)\n",
    "        file_path = './input/state-of-data-brazil-2023⁄State_of_data_BR_2023_Kaggle.csv'\n",
    "    return file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o DataFrame\n",
    "file_path = get_file_path()\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listar Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas do DataFrame:\n",
      "[\"('P0', 'id')\",\n",
      " \"('P1_a ', 'Idade')\",\n",
      " \"('P1_a_1 ', 'Faixa idade')\",\n",
      " \"('P1_b ', 'Genero')\",\n",
      " \"('P1_c ', 'Cor/raca/etnia')\",\n",
      " \"('P1_d ', 'PCD')\",\n",
      " \"('P1_e ', 'experiencia_profissional_prejudicada')\",\n",
      " \"('P1_e_1 ', 'Não acredito que minha experiência profissional seja afetada')\",\n",
      " \"('P1_e_2 ', 'Experiencia prejudicada devido a minha Cor Raça Etnia')\",\n",
      " \"('P1_e_3 ', 'Experiencia prejudicada devido a minha identidade de gênero')\",\n",
      " \"('P1_e_4 ', 'Experiencia prejudicada devido ao fato de ser PCD')\",\n",
      " \"('P1_f ', 'aspectos_prejudicados')\",\n",
      " \"('P1_f_1', 'Quantidade de oportunidades de emprego/vagas recebidas')\",\n",
      " \"('P1_f_2', 'Senioridade das vagas recebidas em relação à sua experiência')\",\n",
      " \"('P1_f_3', 'Aprovação em processos seletivos/entrevistas')\",\n",
      " \"('P1_f_4', 'Oportunidades de progressão de carreira')\",\n",
      " \"('P1_f_5', 'Velocidade de progressão de carreira')\",\n",
      " \"('P1_f_6', 'Nível de cobrança no trabalho/Stress no trabalho')\",\n",
      " \"('P1_f_7', 'Atenção dada diante das minhas opiniões e ideias')\",\n",
      " \"('P1_f_8', 'Relação com outros membros da empresa, em momentos de trabalho')\",\n",
      " \"('P1_f_9', 'Relação com outros membros da empresa, em momentos de integração \"\n",
      " \"e outros momentos fora do trabalho')\",\n",
      " \"('P1_g ', 'vive_no_brasil')\",\n",
      " \"('P1_i ', 'Estado onde mora')\",\n",
      " \"('P1_i_1 ', 'uf onde mora')\",\n",
      " \"('P1_i_2 ', 'Regiao onde mora')\",\n",
      " \"('P1_j ', 'Mudou de Estado?')\",\n",
      " \"('P1_k ', 'Regiao de origem')\",\n",
      " \"('P1_l ', 'Nivel de Ensino')\",\n",
      " \"('P1_m ', 'Área de Formação')\",\n",
      " \"('P2_a ', 'Qual sua situação atual de trabalho?')\",\n",
      " \"('P2_b ', 'Setor')\",\n",
      " \"('P2_c ', 'Numero de Funcionarios')\",\n",
      " \"('P2_d ', 'Gestor?')\",\n",
      " \"('P2_e ', 'Cargo como Gestor')\",\n",
      " \"('P2_f ', 'Cargo Atual')\",\n",
      " \"('P2_g ', 'Nivel')\",\n",
      " \"('P2_h ', 'Faixa salarial')\",\n",
      " \"('P2_i ', 'Quanto tempo de experiência na área de dados você tem?')\",\n",
      " \"('P2_j ', 'Quanto tempo de experiência na área de TI/Engenharia de Software \"\n",
      " \"você teve antes de começar a trabalhar na área de dados?')\",\n",
      " \"('P2_k ', 'Você está satisfeito na sua empresa atual?')\",\n",
      " \"('P2_l ', 'Qual o principal motivo da sua insatisfação com a empresa \"\n",
      " \"atual?')\",\n",
      " \"('P2_l_1 ', 'Falta de oportunidade de crescimento no emprego atual')\",\n",
      " \"('P2_l_2 ', 'Salário atual não corresponde ao mercado')\",\n",
      " \"('P2_l_3 ', 'Não tenho uma boa relação com meu líder/gestor')\",\n",
      " \"('P2_l_4 ', 'Gostaria de trabalhar em em outra área de atuação')\",\n",
      " \"('P2_l_5 ', 'Gostaria de receber mais benefícios')\",\n",
      " \"('P2_l_6 ', 'O clima de trabalho/ambiente não é bom')\",\n",
      " \"('P2_l_7 ', 'Falta de maturidade analítica na empresa')\",\n",
      " \"('P2_m ', 'Você participou de entrevistas de emprego nos últimos 6 meses?')\",\n",
      " \"('P2_n ', 'Você pretende mudar de emprego nos próximos 6 meses?')\",\n",
      " \"('P2_o ', 'Quais os principais critérios que você leva em consideração no \"\n",
      " \"momento de decidir onde trabalhar?')\",\n",
      " \"('P2_o_1 ', 'Remuneração/Salário')\",\n",
      " \"('P2_o_2 ', 'Benefícios')\",\n",
      " \"('P2_o_3 ', 'Propósito do trabalho e da empresa')\",\n",
      " \"('P2_o_4 ', 'Flexibilidade de trabalho remoto')\",\n",
      " \"('P2_o_5 ', 'Ambiente e clima de trabalho')\",\n",
      " \"('P2_o_6 ', 'Oportunidade de aprendizado e trabalhar com referências na \"\n",
      " \"área')\",\n",
      " \"('P2_o_7 ', 'Plano de carreira e oportunidades de crescimento profissional')\",\n",
      " \"('P2_o_8 ', 'Maturidade da empresa em termos de tecnologia e dados')\",\n",
      " \"('P2_o_9 ', 'Qualidade dos gestores e líderes')\",\n",
      " \"('P2_o_10 ', 'Reputação que a empresa tem no mercado')\",\n",
      " \"('P2_q ', 'Empresa que trabaha passou por layoff em 2023')\",\n",
      " \"('P2_r ', 'Atualmente qual a sua forma de trabalho?')\",\n",
      " \"('P2_s ', 'Qual a forma de trabalho ideal para você?')\",\n",
      " \"('P2_t ', 'Caso sua empresa decida pelo modelo 100% presencial qual será sua \"\n",
      " \"atitude?')\",\n",
      " \"('P3_a ', 'Qual o número aproximado de pessoas que atuam com dados na sua \"\n",
      " \"empresa hoje?')\",\n",
      " \"('P3_b ', 'Quais desses papéis/cargos fazem parte do time (ou chapter) de \"\n",
      " \"dados da sua empresa?')\",\n",
      " \"('P3_b_1 ', 'Analytics Engineer')\",\n",
      " \"('P3_b_2 ', 'Engenharia de Dados/Data Engineer')\",\n",
      " \"('P3_b_3 ', 'Analista de Dados/Data Analyst')\",\n",
      " \"('P3_b_4 ', 'Cientista de Dados/Data Scientist')\",\n",
      " \"('P3_b_5 ', 'Database Administrator/DBA')\",\n",
      " \"('P3_b_6 ', 'Analista de Business Intelligence/BI')\",\n",
      " \"('P3_b_7 ', 'Arquiteto de Dados/Data Architect')\",\n",
      " \"('P3_b_8 ', 'Data Product Manager/DPM')\",\n",
      " \"('P3_b_9 ', 'Business Analyst')\",\n",
      " \"('P3_c ', 'Quais dessas responsabilidades fazem parte da sua rotina atual de \"\n",
      " \"trabalho como gestor?')\",\n",
      " \"('P3_c_1 ', 'Pensar na visão de longo prazo de dados da empresa e \"\n",
      " \"fortalecimento da cultura analítica da companhia.')\",\n",
      " \"('P3_c_2 ', 'Organização de treinamentos e iniciativas com o objetivo de \"\n",
      " \"aumentar a maturidade analítica das áreas de negócios.')\",\n",
      " \"('P3_c_3 ', 'Atração, seleção e contratação de talentos para o time de \"\n",
      " \"dados.')\",\n",
      " \"('P3_c_4 ', 'Decisão sobre contratação de ferramentas e tecnologias \"\n",
      " \"relacionadas a dados.')\",\n",
      " \"('P3_c_5 ', 'Sou gestor da equipe responsável pela engenharia de dados e por \"\n",
      " 'manter o Data Lake da empresa como fonte única dos dados, garantindo a '\n",
      " \"qualidade e confiabilidade da informação.')\",\n",
      " \"('P3_c_6 ', 'Sou gestor da equipe responsável pela entrega de dados, \"\n",
      " \"estudos, relatórios e dashboards para as áreas de negócio da empresa.')\",\n",
      " \"('P3_c_7 ', 'Sou gestor da equipe responsável por iniciativas e projetos \"\n",
      " \"envolvendo Inteligência Artificial e Machine Learning.')\",\n",
      " \"('P3_c_8 ', 'Apesar de ser gestor ainda atuo na parte técnica, construindo \"\n",
      " \"soluções/análises/modelos etc.')\",\n",
      " \"('P3_c_9 ', 'Gestão de projetos de dados, cuidando das etapas, equipes \"\n",
      " \"envolvidas, atingimento dos objetivos etc.')\",\n",
      " \"('P3_c_10 ', 'Gestão de produtos de dados, cuidando da visão dos produtos, \"\n",
      " \"backlog, feedback de usuários etc.')\",\n",
      " \"('P3_c_11 ', 'Gestão de pessoas, apoio no desenvolvimento das pessoas, \"\n",
      " \"evolução de carreira')\",\n",
      " \"('P3_d ', 'Quais são os 3 maiores desafios que você tem como gestor no atual \"\n",
      " \"momento?')\",\n",
      " \"('P3_d_1 ', 'a Contratar novos talentos.')\",\n",
      " \"('P3_d_2 ', 'b Reter talentos.')\",\n",
      " \"('P3_d_3 ', 'c Convencer a empresa a aumentar os investimentos na área de \"\n",
      " \"dados.')\",\n",
      " \"('P3_d_4 ', 'd Gestão de equipes no ambiente remoto.')\",\n",
      " \"('P3_d_5 ', 'e Gestão de projetos envolvendo áreas multidisciplinares da \"\n",
      " \"empresa.')\",\n",
      " \"('P3_d_6 ', 'f Organizar as informações e garantir a qualidade e \"\n",
      " \"confiabilidade.')\",\n",
      " \"('P3_d_7 ', 'g Conseguir processar e armazenar um alto volume de dados.')\",\n",
      " \"('P3_d_8 ', 'h Conseguir gerar valor para as áreas de negócios através de \"\n",
      " \"estudos e experimentos.')\",\n",
      " \"('P3_d_9 ', 'i Desenvolver e manter modelos Machine Learning em produção.')\",\n",
      " \"('P3_d_10 ', 'j Gerenciar a expectativa das áreas de negócio em relação as \"\n",
      " \"entregas das equipes de dados.')\",\n",
      " \"('P3_d_11 ', 'k Garantir a manutenção dos projetos e modelos em produção, em \"\n",
      " \"meio ao crescimento da empresa.')\",\n",
      " \"('P3_d_12 ', 'Conseguir levar inovação para a empresa através dos dados.')\",\n",
      " \"('P3_d_13 ', 'Garantir retorno do investimento (ROI) em projetos de dados.')\",\n",
      " \"('P3_d_14 ', 'Dividir o tempo entre entregas técnicas e gestão.')\",\n",
      " \"('P3_e ', 'AI Generativa é uma prioridade em sua empresa?')\",\n",
      " \"('P3_f ', 'Tipos de uso de AI Generativa e LLMs na empresa')\",\n",
      " \"('P3_f_1 ', 'Colaboradores usando AI generativa de forma independente e \"\n",
      " \"descentralizada')\",\n",
      " \"('P3_f_2 ', 'Direcionamento centralizado do uso de AI generativa')\",\n",
      " \"('P3_f_3 ', 'Desenvolvedores utilizando Copilots')\",\n",
      " \"('P3_f_4 ', 'AI Generativa e LLMs para melhorar produtos externos')\",\n",
      " \"('P3_f_5 ', 'AI Generativa e LLMs para melhorar produtos internos para os \"\n",
      " \"colaboradores')\",\n",
      " \"('P3_f_6 ', 'IA Generativa e LLMs como principal frente do negócio')\",\n",
      " \"('P3_f_7 ', 'IA Generativa e LLMs não é prioridade')\",\n",
      " \"('P3_f_8 ', 'Não sei opinar sobre o uso de IA Generativa e LLMs na empresa')\",\n",
      " \"('P3_g ', 'Motivos que levam a empresa a não usar AI Genrativa e LLMs')\",\n",
      " \"('P3_g_1 ', 'Falta de compreensão dos casos de uso')\",\n",
      " \"('P3_g_2 ', 'Falta de confiabilidade das saídas (alucinação dos modelos)')\",\n",
      " \"('P3_g_3 ', 'Incerteza em relação a regulamentação')\",\n",
      " \"('P3_g_4 ', 'Preocupações com segurança e privacidade de dados')\",\n",
      " \"('P3_g_5 ', 'Retorno sobre investimento (ROI) não comprovado de IA \"\n",
      " \"Generativa')\",\n",
      " \"('P3_g_6 ', 'Dados da empresa não estão prontos para uso de IA Generativa')\",\n",
      " \"('P3_g_7 ', 'Falta de expertise ou falta de recursos')\",\n",
      " \"('P3_g_8 ', 'Alta direção da empresa não vê valor ou não vê como \"\n",
      " \"prioridade')\",\n",
      " \"('P3_g_9 ', 'Preocupações com propriedade intelectual')\",\n",
      " \"('P4_a ', 'Mesmo que esse não seja seu cargo formal, você considera que sua \"\n",
      " \"atuação no dia a dia, reflete alguma das opções listadas abaixo?')\",\n",
      " \"('P4_a_1 ', 'Atuacao')\",\n",
      " \"('P4_b ', 'Quais das fontes de dados listadas você já analisou ou processou \"\n",
      " \"no trabalho?')\",\n",
      " \"('P4_b_1 ', 'Dados relacionais (estruturados em bancos SQL)')\",\n",
      " \"('P4_b_2 ', 'Dados armazenados em bancos NoSQL')\",\n",
      " \"('P4_b_3 ', 'Imagens')\",\n",
      " \"('P4_b_4 ', 'Textos/Documentos')\",\n",
      " \"('P4_b_5 ', 'Vídeos')\",\n",
      " \"('P4_b_6 ', 'Áudios')\",\n",
      " \"('P4_b_7 ', 'Planilhas')\",\n",
      " \"('P4_b_8 ', 'Dados georeferenciados')\",\n",
      " \"('P4_c ', 'Entre as fontes de dados listadas, quais você utiliza na maior \"\n",
      " \"parte do tempo?')\",\n",
      " \"('P4_c_1 ', 'Dados relacionais (estruturados em bancos SQL)')\",\n",
      " \"('P4_c_2 ', 'Dados armazenados em bancos NoSQL')\",\n",
      " \"('P4_c_3 ', 'Imagens')\",\n",
      " \"('P4_c_4 ', 'Textos/Documentos')\",\n",
      " \"('P4_c_5 ', 'Vídeos')\",\n",
      " \"('P4_c_6 ', 'Áudios')\",\n",
      " \"('P4_c_7 ', 'Planilhas')\",\n",
      " \"('P4_c_8 ', 'Dados georeferenciados')\",\n",
      " \"('P4_d ', 'Quais das linguagens listadas abaixo você utiliza no trabalho?')\",\n",
      " \"('P4_d_1 ', 'SQL')\",\n",
      " \"('P4_d_2 ', 'R ')\",\n",
      " \"('P4_d_3 ', 'Python')\",\n",
      " \"('P4_d_4 ', 'C/C++/C#')\",\n",
      " \"('P4_d_5 ', '.NET')\",\n",
      " \"('P4_d_6 ', 'Java')\",\n",
      " \"('P4_d_7 ', 'Julia')\",\n",
      " \"('P4_d_8 ', 'SAS/Stata')\",\n",
      " \"('P4_d_9 ', 'Visual Basic/VBA')\",\n",
      " \"('P4_d_10 ', 'Scala')\",\n",
      " \"('P4_d_11 ', 'Matlab')\",\n",
      " \"('P4_d_12 ', 'Rust')\",\n",
      " \"('P4_d_13 ', 'PHP')\",\n",
      " \"('P4_d_14 ', 'JavaScript')\",\n",
      " \"('P4_d_15 ', 'Não utilizo nenhuma linguagem')\",\n",
      " \"('P4_e ', 'Entre as linguagens listadas abaixo, qual é a que você mais \"\n",
      " \"utiliza no trabalho?')\",\n",
      " \"('P4_f ', 'Entre as linguagens listadas abaixo, qual é a sua preferida?')\",\n",
      " \"('P4_g ', 'Quais dos bancos de dados/fontes de dados listados abaixo você \"\n",
      " \"utiliza no trabalho?')\",\n",
      " \"('P4_g_1 ', 'MySQL')\",\n",
      " \"('P4_g_2 ', 'Oracle')\",\n",
      " \"('P4_g_3 ', 'SQL SERVER')\",\n",
      " \"('P4_g_4 ', 'Amazon Aurora ou RDS')\",\n",
      " \"('P4_g_5 ', 'DynamoDB')\",\n",
      " \"('P4_g_6 ', 'CoachDB')\",\n",
      " \"('P4_g_7 ', 'Cassandra')\",\n",
      " \"('P4_g_8 ', 'MongoDB')\",\n",
      " \"('P4_g_9 ', 'MariaDB')\",\n",
      " \"('P4_g_10 ', 'Datomic')\",\n",
      " \"('P4_g_11 ', 'S3')\",\n",
      " \"('P4_g_12 ', 'PostgreSQL')\",\n",
      " \"('P4_g_13 ', 'ElasticSearch')\",\n",
      " \"('P4_g_14 ', 'DB2')\",\n",
      " \"('P4_g_15 ', 'Microsoft Access')\",\n",
      " \"('P4_g_16 ', 'SQLite')\",\n",
      " \"('P4_g_17 ', 'Sybase')\",\n",
      " \"('P4_g_18 ', 'Firebase')\",\n",
      " \"('P4_g_19 ', 'Vertica')\",\n",
      " \"('P4_g_20 ', 'Redis')\",\n",
      " \"('P4_g_21 ', 'Neo4J')\",\n",
      " \"('P4_g_22 ', 'Google BigQuery')\",\n",
      " \"('P4_g_23 ', 'Google Firestore')\",\n",
      " \"('P4_g_24 ', 'Amazon Redshift')\",\n",
      " \"('P4_g_25 ', 'Amazon Athena')\",\n",
      " \"('P4_g_26 ', 'Snowflake')\",\n",
      " \"('P4_g_27 ', 'Databricks')\",\n",
      " \"('P4_g_28 ', 'HBase')\",\n",
      " \"('P4_g_29 ', 'Presto')\",\n",
      " \"('P4_g_30 ', 'Splunk')\",\n",
      " \"('P4_g_31 ', 'SAP HANA')\",\n",
      " \"('P4_g_32 ', 'Hive')\",\n",
      " \"('P4_g_33 ', 'Firebird')\",\n",
      " \"('P4_h ', 'Dentre as opções listadas, qual sua Cloud preferida?')\",\n",
      " \"('P4_h_1 ', 'Azure (Microsoft)')\",\n",
      " \"('P4_h_2 ', 'Amazon Web Services (AWS)')\",\n",
      " \"('P4_h_3 ', 'Google Cloud (GCP)')\",\n",
      " \"('P4_h_4 ', 'Oracle Cloud')\",\n",
      " \"('P4_h_5 ', 'IBM')\",\n",
      " \"('P4_h_6 ', 'Servidores On Premise/Não utilizamos Cloud')\",\n",
      " \"('P4_h_7 ', 'Cloud Própria')\",\n",
      " \"('P4_i ', 'Cloud preferida')\",\n",
      " \"('P4_j ', 'Ferramenta de BI utilizada no dia a dia')\",\n",
      " \"('P4_j_1 ', 'Microsoft PowerBI')\",\n",
      " \"('P4_j_2 ', 'Qlik View/Qlik Sense')\",\n",
      " \"('P4_j_3 ', 'Tableau')\",\n",
      " \"('P4_j_4 ', 'Metabase')\",\n",
      " \"('P4_j_5 ', 'Superset')\",\n",
      " \"('P4_j_6 ', 'Redash')\",\n",
      " \"('P4_j_7 ', 'Looker')\",\n",
      " \"('P4_j_8 ', 'Looker Studio(Google Data Studio)')\",\n",
      " \"('P4_j_9 ', 'Amazon Quicksight')\",\n",
      " \"('P4_j_10 ', 'Mode')\",\n",
      " \"('P4_j_11 ', 'Alteryx')\",\n",
      " \"('P4_j_12 ', 'MicroStrategy')\",\n",
      " \"('P4_j_13 ', 'IBM Analytics/Cognos')\",\n",
      " \"('P4_j_14 ', 'SAP Business Objects/SAP Analytics')\",\n",
      " \"('P4_j_15 ', 'Oracle Business Intelligence')\",\n",
      " \"('P4_j_16 ', 'Salesforce/Einstein Analytics')\",\n",
      " \"('P4_j_17 ', 'Birst')\",\n",
      " \"('P4_j_18 ', 'SAS Visual Analytics')\",\n",
      " \"('P4_j_19 ', 'Grafana')\",\n",
      " \"('P4_j_20 ', 'TIBCO Spotfire')\",\n",
      " \"('P4_j_21 ', 'Pentaho')\",\n",
      " \"('P4_j_22 ', 'Fazemos todas as análises utilizando apenas Excel ou planilhas \"\n",
      " \"do google')\",\n",
      " \"('P4_j_23 ', 'Não utilizo nenhuma ferramenta de BI no trabalho')\",\n",
      " \"('P4_k ', 'Qual sua ferramenta de BI preferida?')\",\n",
      " \"('P4_l ', 'Qual o tipo de uso de AI Generativa e LLMs na empresa')\",\n",
      " \"('P4_l_1 ', 'Colaboradores usando AI generativa de forma independente e \"\n",
      " \"descentralizada')\",\n",
      " \"('P4_l_2 ', 'Direcionamento centralizado do uso de AI generativa')\",\n",
      " \"('P4_l_3 ', 'Desenvolvedores utilizando Copilots')\",\n",
      " \"('P4_l_4 ', 'AI Generativa e LLMs para melhorar produtos externos para os \"\n",
      " \"clientes finais')\",\n",
      " \"('P4_l_5 ', 'AI Generativa e LLMs para melhorar produtos internos para os \"\n",
      " \"colaboradores')\",\n",
      " \"('P4_l_6 ', 'IA Generativa e LLMs como principal frente do negócio')\",\n",
      " \"('P4_l_7 ', 'IA Generativa e LLMs não é prioridade')\",\n",
      " \"('P4_l_8 ', 'Não sei opinar sobre o uso de IA Generativa e LLMs na empresa')\",\n",
      " \"('P4_m ', 'Utiliza ChatGPT ou LLMs no trabalho?')\",\n",
      " \"('P4_m_1 ', 'Não uso soluções de AI Generativa com foco em produtividade')\",\n",
      " \"('P4_m_2 ', 'Uso soluções gratuitas de AI Generativa com foco em \"\n",
      " \"produtividade')\",\n",
      " \"('P4_m_3 ', 'Uso e pago pelas soluções de AI Generativa com foco em \"\n",
      " \"produtividade')\",\n",
      " \"('P4_m_4 ', 'A empresa que trabalho paga pelas soluções de AI Generativa com \"\n",
      " \"foco em produtividade')\",\n",
      " \"('P4_m_5 ', 'Uso soluções do tipo Copilot')\",\n",
      " \"('P5_a ', 'Qual seu objetivo na área de dados?')\",\n",
      " \"('P5_b ', 'Qual oportunidade você está buscando?')\",\n",
      " \"('P5_c ', 'Há quanto tempo você busca uma oportunidade na área de dados?')\",\n",
      " \"('P5_d ', 'Como tem sido a busca por um emprego na área de dados?')\",\n",
      " \"('P6_a ', 'Quais das opções abaixo fazem parte da sua rotina no trabalho \"\n",
      " \"atual como engenheiro de dados?')\",\n",
      " \"('P6_a_1 ', 'Desenvolvo pipelines de dados utilizando linguagens de \"\n",
      " \"programação como Python, Scala, Java etc.')\",\n",
      " \"('P6_a_2 ', 'Realizo construções de ETL's em ferramentas como Pentaho, \"\n",
      " \"Talend, Dataflow etc.')\",\n",
      " \"('P6_a_3 ', 'Crio consultas através da linguagem SQL para exportar \"\n",
      " \"informações e compartilhar com as áreas de negócio.')\",\n",
      " \"('P6_a_4 ', 'Atuo na integração de diferentes fontes de dados através de \"\n",
      " \"plataformas proprietárias como Stitch Data, Fivetran etc.')\",\n",
      " \"('P6_a_5 ', 'Modelo soluções de arquitetura de dados, criando componentes de \"\n",
      " \"ingestão de dados, transformação e recuperação da informação.')\",\n",
      " \"('P6_a_6 ', 'Desenvolvo/cuido da manutenção de repositórios de dados \"\n",
      " \"baseados em streaming de eventos como Data Lakes e Data Lakehouses.')\",\n",
      " \"('P6_a_7 ', 'Atuo na modelagem dos dados, com o objetivo de criar conjuntos \"\n",
      " \"de dados como Data Warehouses, Data Marts etc.')\",\n",
      " \"('P6_a_8 ', 'Cuido da qualidade dos dados, metadados e dicionário de \"\n",
      " \"dados.')\",\n",
      " \"('P6_a_9 ', 'Nenhuma das opções listadas refletem meu dia a dia.')\",\n",
      " \"('P6_b ', 'Quais as ferramentas/tecnologias de ETL que você utiliza no \"\n",
      " \"trabalho como Data Engineer?')\",\n",
      " \"('P6_b_1 ', 'Scripts Python')\",\n",
      " \"('P6_b_2 ', 'SQL & Stored Procedures')\",\n",
      " \"('P6_b_3 ', 'Apache Airflow')\",\n",
      " \"('P6_b_4 ', 'Apache NiFi')\",\n",
      " \"('P6_b_5 ', 'Luigi')\",\n",
      " \"('P6_b_6 ', 'AWS Glue')\",\n",
      " \"('P6_b_7 ', 'Talend')\",\n",
      " \"('P6_b_8 ', 'Pentaho')\",\n",
      " \"('P6_b_9 ', 'Alteryx')\",\n",
      " \"('P6_b_10 ', 'Stitch')\",\n",
      " \"('P6_b_11 ', 'Fivetran')\",\n",
      " \"('P6_b_12 ', 'Google Dataflow')\",\n",
      " \"('P6_b_13 ', 'Oracle Data Integrator')\",\n",
      " \"('P6_b_14 ', 'IBM DataStage')\",\n",
      " \"('P6_b_15 ', 'SAP BW ETL')\",\n",
      " \"('P6_b_16 ', 'SQL Server Integration Services (SSIS))\",\n",
      " \"('P6_b_17 ', 'SAS Data Integration')\",\n",
      " \"('P6_b_18 ', 'Qlik Sense')\",\n",
      " \"('P6_b_19 ', 'Knime')\",\n",
      " \"('P6_b_20 ', 'Databricks')\",\n",
      " \"('P6_b_21 ', 'Não utilizo ferramentas de ETL')\",\n",
      " \"('P6_c ', 'Sua organização possui um Data Lake?')\",\n",
      " \"('P6_d ', 'Qual tecnologia utilizada como plataforma do Data Lake?')\",\n",
      " \"('P6_e ', 'Sua organização possui um Data Warehouse?')\",\n",
      " \"('P6_f ', 'Qual tecnologia utilizada como plataforma do Data Warehouse?')\",\n",
      " \"('P6_g ', 'Quais as ferramentas de gestão de Qualidade de dados, Metadados e \"\n",
      " \"catálogo de dados você utiliza no trabalho?')\",\n",
      " \"('P6_h ', 'Em qual das opções abaixo você gasta a maior parte do seu \"\n",
      " \"tempo?')\",\n",
      " \"('P6_h_1 ', 'Desenvolvendo pipelines de dados utilizando linguagens de \"\n",
      " \"programação como Python, Scala, Java etc.')\",\n",
      " \"('P6_h_2 ', 'Realizando construções de ETL's em ferramentas como Pentaho, \"\n",
      " \"Talend, Dataflow etc.')\",\n",
      " \"('P6_h_3 ', 'Criando consultas através da linguagem SQL para exportar \"\n",
      " \"informações e compartilhar com as áreas de negócio.')\",\n",
      " \"('P6_h_4 ', 'Atuando na integração de diferentes fontes de dados através de \"\n",
      " \"plataformas proprietárias como Stitch Data, Fivetran etc.')\",\n",
      " \"('P6_h_5 ', 'Modelando soluções de arquitetura de dados, criando componentes \"\n",
      " \"de ingestão de dados, transformação e recuperação da informação.')\",\n",
      " \"('P6_h_6 ', 'Desenvolvendo/cuidando da manutenção de repositórios de dados \"\n",
      " \"baseados em streaming de eventos como Data Lakes e Data Lakehouses.')\",\n",
      " \"('P6_h_7 ', 'Atuando na modelagem dos dados, com o objetivo de criar \"\n",
      " \"conjuntos de dados como Data Warehouses, Data Marts etc.')\",\n",
      " \"('P6_h_8 ', 'Cuidando da qualidade dos dados, metadados e dicionário de \"\n",
      " \"dados.')\",\n",
      " \"('P6_h_9 ', 'Nenhuma das opções listadas refletem meu dia a dia.')\",\n",
      " \"('P7_1 ', 'Quais das opções abaixo fazem parte da sua rotina no trabalho \"\n",
      " \"atual com análise de dados?')\",\n",
      " \"('P7_a_1 ', 'Processo e analiso dados utilizando linguagens de programação \"\n",
      " \"como Python, R etc.')\",\n",
      " \"('P7_a_2 ', 'Realizo construções de dashboards em ferramentas de BI como \"\n",
      " \"PowerBI, Tableau, Looker, Qlik etc.')\",\n",
      " \"('P7_a_3 ', 'Crio consultas através da linguagem SQL para exportar \"\n",
      " \"informações e compartilhar com as áreas de negócio.')\",\n",
      " \"('P7_a_4 ', 'Utilizo API's para extrair dados e complementar minhas \"\n",
      " \"análises.')\",\n",
      " \"('P7_a_5 ', 'Realizo experimentos e estudos utilizando metodologias \"\n",
      " \"estatísticas como teste de hipótese, modelos de regressão etc.')\",\n",
      " \"('P7_a_6 ', 'Desenvolvo/cuido da manutenção de ETL's utilizando tecnologias \"\n",
      " \"como Talend, Pentaho, Airflow, Dataflow etc.')\",\n",
      " \"('P7_a_7 ', 'Atuo na modelagem dos dados, com o objetivo de criar conjuntos \"\n",
      " \"de dados, Data Warehouses, Data Marts etc.')\",\n",
      " \"('P7_a_8 ', 'Desenvolvo/cuido da manutenção de planilhas para atender as \"\n",
      " \"áreas de negócio.')\",\n",
      " \"('P7_a_9 ', 'Utilizo ferramentas avançadas de estatística como SASS, PSS, \"\n",
      " \"Stata etc')\",\n",
      " \"('P7_a_10 ', 'Nenhuma das opções listadas refletem meu dia a dia.')\",\n",
      " \"('P7_b ', 'Quais as ferramentas/tecnologias de ETL que você utiliza no \"\n",
      " \"trabalho como Data Analyst?')\",\n",
      " \"('P7_b_1 ', 'Scripts Python')\",\n",
      " \"('P7_b_2 ', 'SQL & Stored Procedures')\",\n",
      " \"('P7_b_3 ', 'Apache Airflow')\",\n",
      " \"('P7_b_4 ', 'Apache NiFi')\",\n",
      " \"('P7_b_5 ', 'Luigi')\",\n",
      " \"('P7_b_6 ', 'AWS Glue')\",\n",
      " \"('P7_b_7 ', 'Talend')\",\n",
      " \"('P7_b_8 ', 'Pentaho')\",\n",
      " \"('P7_b_9 ', 'Alteryx')\",\n",
      " \"('P7_b_10 ', 'Stitch')\",\n",
      " \"('P7_b_11 ', 'Fivetran')\",\n",
      " \"('P7_b_12 ', 'Google Dataflow')\",\n",
      " \"('P7_b_13 ', 'Oracle Data Integrator')\",\n",
      " \"('P7_b_14 ', 'IBM DataStage')\",\n",
      " \"('P7_b_15 ', 'SAP BW ETL')\",\n",
      " \"('P7_b_16 ', 'SQL Server Integration Services (SSIS)')\",\n",
      " \"('P7_b_17 ', 'SAS Data Integration')\",\n",
      " \"('P7_b_18 ', 'Qlik Sense')\",\n",
      " \"('P7_b_19 ', 'Knime')\",\n",
      " \"('P7_b_20 ', 'Databricks')\",\n",
      " \"('P7_b_21 ', 'Não utilizo ferramentas de ETL')\",\n",
      " \"('P7_c ', 'Sua empresa utiliza alguma das ferramentas listadas para dar mais \"\n",
      " \"autonomia em análise de dados para as áreas de negócio?')\",\n",
      " \"('P7_c_1 ', 'Ferramentas de AutoML como H2O.ai, Data Robot, BigML etc.')\",\n",
      " '(\\'P7_c_2 \\', \\'\"\"Point and Click\"\" Analytics como Alteryx, Knime, '\n",
      " \"Rapidminer etc.')\",\n",
      " \"('P7_c_3 ', 'Product metricts & Insights como Mixpanel, Amplitude, Adobe \"\n",
      " \"Analytics.')\",\n",
      " \"('P7_c_4 ', 'Ferramentas de análise dentro de ferramentas de CRM como \"\n",
      " \"Salesforce Einstein Anaytics ou Zendesk dashboards.')\",\n",
      " \"('P7_c_5 ', 'Minha empresa não utiliza essas ferramentas.')\",\n",
      " \"('P7_c_6 ', 'Não sei informar.')\",\n",
      " \"('P7_d ', 'Em qual das opções abaixo você gasta a maior parte do seu tempo \"\n",
      " \"de trabalho?')\",\n",
      " \"('P7_d_1 ', 'Processando e analisando dados utilizando linguagens de \"\n",
      " \"programação como Python, R etc.')\",\n",
      " \"('P7_d_2 ', 'Realizando construções de dashboards em ferramentas de BI como \"\n",
      " \"PowerBI, Tableau, Looker, Qlik etc.')\",\n",
      " \"('P7_d_3 ', 'Criando consultas através da linguagem SQL para exportar \"\n",
      " \"informações e compartilhar com as áreas de negócio.')\",\n",
      " \"('P7_d_4 ', 'Utilizando API's para extrair dados e complementar minhas \"\n",
      " \"análises.')\",\n",
      " \"('P7_d_5 ', 'Realizando experimentos e estudos utilizando metodologias \"\n",
      " \"estatísticas como teste de hipótese, modelos de regressão etc.')\",\n",
      " \"('P7_d_6 ', 'Desenvolvendo/cuidando da manutenção de ETL's utilizando \"\n",
      " \"tecnologias como Talend, Pentaho, Airflow, Dataflow etc.')\",\n",
      " \"('P7_d_7 ', 'Atuando na modelagem dos dados, com o objetivo de criar \"\n",
      " \"conjuntos de dados, Data Warehouses, Data Marts etc.')\",\n",
      " \"('P7_d_8 ', 'Desenvolvendo/cuidando da manutenção de planilhas do Excel ou \"\n",
      " \"Google Sheets para atender as áreas de negócio.')\",\n",
      " \"('P7_d_9 ', 'Utilizando ferramentas avançadas de estatística como SAS, SPSS, \"\n",
      " \"Stata etc, para realizar análises.')\",\n",
      " \"('P7_d_10 ', 'Nenhuma das opções listadas refletem meu dia a dia.')\",\n",
      " \"('P8_a ', 'Quais das opções abaixo fazem parte da sua rotina no trabalho \"\n",
      " \"atual com ciência de dados?')\",\n",
      " \"('P8_a_1 ', 'Estudos Ad-hoc com o objetivo de confirmar hipóteses, realizar \"\n",
      " 'modelos preditivos, forecasts, análise de cluster para resolver problemas '\n",
      " \"pontuais e responder perguntas das áreas de negócio.')\",\n",
      " \"('P8_a_2 ', 'Sou responsável pela coleta e limpeza dos dados que uso para \"\n",
      " \"análise e modelagem.')\",\n",
      " \"('P8_a_3 ', 'Sou responsável por entrar em contato com os times de negócio \"\n",
      " 'para definição do problema, identificar a solução e apresentação de '\n",
      " \"resultados.')\",\n",
      " \"('P8_a_4 ', 'Desenvolvo modelos de Machine Learning com o objetivo de \"\n",
      " \"colocar em produção em sistemas (produtos de dados).')\",\n",
      " \"('P8_a_5 ', 'Sou responsável por colocar modelos em produção, criar os \"\n",
      " \"pipelines de dados, APIs de consumo e monitoramento.')\",\n",
      " \"('P8_a_6 ', 'Cuido da manutenção de modelos de Machine Learning já em \"\n",
      " 'produção, atuando no monitoramento, ajustes e refatoração quando '\n",
      " \"necessário.')\",\n",
      " \"('P8_a_7 ', 'Realizo construções de dashboards em ferramentas de BI como \"\n",
      " \"PowerBI, Tableau, Looker, Qlik, etc')\",\n",
      " \"('P8_a_8 ', 'Utilizo ferramentas avançadas de estatística como SAS, SPSS, \"\n",
      " \"Stata etc, para realizar análises estatísticas e ajustar modelos.')\",\n",
      " \"('P8_a_9 ', 'Crio e dou manutenção em ETLs, DAGs e automações de pipelines \"\n",
      " \"de dados.')\",\n",
      " \"('P8_a_10 ', 'Crio e gerencio soluções de Feature Store e cultura de \"\n",
      " \"MLOps.')\",\n",
      " \"('P8_a_11 ', 'Sou responsável por criar e manter a infra que meus modelos e \"\n",
      " \"soluções rodam (clusters, servidores, API, containers, etc.)')\",\n",
      " \"('P8_a_12 ', 'Treino e aplico LLM's para solucionar problemas de negócio.')\",\n",
      " \"('P8_b ', 'Quais as técnicas e métodos listados abaixo você costuma utilizar \"\n",
      " \"no trabalho?')\",\n",
      " \"('P8_b_1 ', 'Utilizo modelos de regressão (linear, logística, GLM)')\",\n",
      " \"('P8_b_2 ', 'Utilizo redes neurais ou modelos baseados em árvore para criar \"\n",
      " \"modelos de classificação')\",\n",
      " \"('P8_b_3 ', 'Desenvolvo sistemas de recomendação (RecSys)')\",\n",
      " \"('P8_b_4 ', 'Utilizo métodos estatísticos Bayesianos para analisar dados')\",\n",
      " \"('P8_b_5 ', 'Utilizo técnicas de NLP (Natural Language Processing) para \"\n",
      " \"análisar dados não-estruturados')\",\n",
      " \"('P8_b_6 ', 'Utilizo métodos estatísticos clássicos (Testes de hipótese, \"\n",
      " 'análise multivariada, sobrevivência, dados longitudinais, inferência '\n",
      " \"estatistica) para analisar dados')\",\n",
      " \"('P8_b_7 ', 'Utilizo cadeias de Markov ou HMM's para realizar análises de \"\n",
      " \"dados')\",\n",
      " \"('P8_b_8 ', 'Desenvolvo técnicas de Clusterização (K-means, Spectral, DBScan \"\n",
      " \"etc)')\",\n",
      " \"('P8_b_9 ', 'Realizo previsões através de modelos de Séries Temporais (Time \"\n",
      " \"Series)')\",\n",
      " \"('P8_b_10 ', 'Utilizo modelos de Reinforcement Learning (aprendizado por \"\n",
      " \"reforço)')\",\n",
      " \"('P8_b_11 ', 'Utilizo modelos de Machine Learning para detecção de fraude')\",\n",
      " \"('P8_b_12 ', 'Utilizo métodos de Visão Computacional')\",\n",
      " \"('P8_b_13 ', 'Utilizo modelos de Detecção de Churn')\",\n",
      " \"('P8_b_14 ', 'Utilizo LLM's para solucionar problemas de negócio')\",\n",
      " \"('P8_3 ', 'Quais dessas tecnologias fazem parte do seu dia a dia como \"\n",
      " \"cientista de dados?')\",\n",
      " \"('P8_c_1 ', 'Ferramentas de BI (PowerBI, Looker, Tableau, Qlik etc)')\",\n",
      " \"('P8_c_2 ', 'Planilhas (Excel, Google Sheets etc)')\",\n",
      " \"('P8_c_3 ', 'Ambientes de desenvolvimento local (R-studio, JupyterLab, \"\n",
      " \"Anaconda)')\",\n",
      " \"('P8_c_4 ', 'Ambientes de desenvolvimento na nuvem (Google Colab, AWS \"\n",
      " \"Sagemaker, Kaggle Notebooks etc)')\",\n",
      " \"('P8_c_5 ', 'Ferramentas de AutoML (Datarobot, H2O, Auto-Keras etc)')\",\n",
      " \"('P8_c_6 ', 'Ferramentas de ETL (Apache Airflow, NiFi, Stitch, Fivetran, \"\n",
      " \"Pentaho etc)')\",\n",
      " \"('P8_c_7 ', 'Plataformas de Machine Learning (TensorFlow, Azure Machine \"\n",
      " \"Learning, Kubeflow etc)')\",\n",
      " \"('P8_c_8 ', 'Feature Store (Feast, Hopsworks, AWS Feature Store, Databricks \"\n",
      " \"Feature Store etc)')\",\n",
      " \"('P8_c_9 ', 'Sistemas de controle de versão (Github, DVC, Neptune, Gitlab \"\n",
      " \"etc)')\",\n",
      " \"('P8_c_10 ', 'Plataformas de Data Apps (Streamlit, Shiny, Plotly Dash etc)')\",\n",
      " \"('P8_c_11 ', 'Ferramentas de estatística avançada como SPSS, SAS, etc.')\",\n",
      " \"('P8_d ', 'Em qual das opções abaixo você gasta a maior parte do seu tempo \"\n",
      " \"no trabalho?')\",\n",
      " \"('P8_d_1 ', 'Estudos Ad-hoc com o objetivo de confirmar hipóteses, realizar \"\n",
      " 'modelos preditivos, forecasts, análise de cluster para resolver problemas '\n",
      " \"pontuais e responder perguntas das áreas de negócio.')\",\n",
      " \"('P8_d_2 ', 'Coletando e limpando os dados que uso para análise e \"\n",
      " \"modelagem.')\",\n",
      " \"('P8_d_3 ', 'Entrando em contato com os times de negócio para definição do \"\n",
      " \"problema, identificar a solução e apresentação de resultados.')\",\n",
      " \"('P8_d_4 ', 'Desenvolvendo modelos de Machine Learning com o objetivo de \"\n",
      " \"colocar em produção em sistemas (produtos de dados).')\",\n",
      " \"('P8_d_5 ', 'Colocando modelos em produção, criando os pipelines de dados, \"\n",
      " \"APIs de consumo e monitoramento.')\",\n",
      " \"('P8_d_6 ', 'Cuidando da manutenção de modelos de Machine Learning já em \"\n",
      " 'produção, atuando no monitoramento, ajustes e refatoração quando '\n",
      " \"necessário.')\",\n",
      " \"('P8_d_7 ', 'Realizando construções de dashboards em ferramentas de BI como \"\n",
      " \"PowerBI, Tableau, Looker, Qlik, etc.')\",\n",
      " \"('P8_d_8 ', 'Utilizando ferramentas avançadas de estatística como SAS, SPSS, \"\n",
      " \"Stata etc, para realizar análises.')\",\n",
      " \"('P8_d_9 ', 'Criando e dando manutenção em ETLs, DAGs e automações de \"\n",
      " \"pipelines de dados.')\",\n",
      " \"('P8_d_10 ', 'Criando e gerenciando soluções de Feature Store e cultura de \"\n",
      " \"MLOps.')\",\n",
      " \"('P8_d_11 ', 'Criando e mantendo a infra que meus modelos e soluções rodam \"\n",
      " \"(clusters, servidores, API, containers, etc.)')\",\n",
      " \"('P8_d_12 ', 'Treinando e aplicando LLM's para solucionar problemas de \"\n",
      " \"negócio.')\"]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Listar os nomes das colunas no DataFrame de forma legível\n",
    "columns = df.columns.tolist()\n",
    "print(\"Colunas do DataFrame:\")\n",
    "pprint(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise Univariada Funções\n",
    "1.1 Distribuição de Variável Qualitativa  \n",
    "1.2 Distribuição de Variável Quantitativa  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise Qualitativa de Colunas\n",
    "def analyze_quali_column(column_name):\n",
    "    print(f\"Análise da Coluna: {column_name}\")\n",
    "    print(f\"Valores Únicos: {df[column_name].unique()}\")\n",
    "    print(f\"Quantidade de Valores Únicos: {df[column_name].nunique()}\")\n",
    "    print(f\"Quantidade de Valores Nulos: {df[column_name].isnull().sum()}\")\n",
    "    print(f\"Valores Nulos: {df[column_name][df[column_name].isnull()]}\")\n",
    "    print(f\"Contagem de Frequência dos Valores: {df[column_name].value_counts()}\")\n",
    "    print(\"\\n\")\n",
    "    return\n",
    "\n",
    "def make_graph_column(column_name):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.countplot(data=df, x=column_name, order = df[column_name].value_counts().index)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "# Análise Quantitativa de Colunas\n",
    "def analyze_quanti_column(column_name):\n",
    "    print(f\"Análise da Coluna: {column_name}\")\n",
    "    print(f\"Valores Únicos: {df[column_name].unique()}\")\n",
    "    print(f\"Quantidade de Valores Únicos: {df[column_name].nunique()}\")\n",
    "    print(f\"Quantidade de Valores Nulos: {df[column_name].isnull().sum()}\")\n",
    "    print(f\"Valores Nulos: {df[column_name][df[column_name].isnull()]}\")\n",
    "    print(f\"Média: {df[column_name].mean()}\")\n",
    "    print(f\"Mediana: {df[column_name].median()}\")\n",
    "    print(f\"Desvio Padrão: {df[column_name].std()}\")\n",
    "    print(f\"Valor Mínimo: {df[column_name].min()}\")\n",
    "    print(f\"Valor Máximo: {df[column_name].max()}\")\n",
    "    print(\"\\n\")\n",
    "    return\n",
    "\n",
    "def make_histogram_column(column_name):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    df[column_name].dropna().plot(kind='hist', bins=20, edgecolor='black')\n",
    "    plt.title(f'Distribuição da Variável Quantitativa: {column_name}')\n",
    "    plt.xlabel(column_name)\n",
    "    plt.ylabel('Frequência')\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplos de análise de colunas\n",
    "\n",
    "# Análise qualitativa\n",
    "analyze_quali_column(\"('P1_b ', 'Genero')\")\n",
    "make_graph_column(\"('P1_b ', 'Genero')\")\n",
    "\n",
    "# Análise quantitativa\n",
    "analyze_quanti_column(\"('P1_a ', 'Idade')\")\n",
    "make_histogram_column(\"('P1_a ', 'Idade')\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5242826,
     "sourceId": 8734113,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
